{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path_train = \"./Data/train/\"\n",
    "src_path_valid = \"./Data/valid/\"\n",
    "src_path_test = \"./Data/test/\"\n",
    "\n",
    "scale=1 / 255.0\n",
    "rotation=20\n",
    "zoom=0.05\n",
    "width_shift=0.05\n",
    "height_shift=0.05\n",
    "shear=0.05\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        dtype='float32',\n",
    "        rescale=scale,\n",
    "        rotation_range=rotation,\n",
    "        zoom_range=zoom,\n",
    "        width_shift_range=width_shift,\n",
    "        height_shift_range=width_shift,\n",
    "        shear_range=shear,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "        dtype='float32',\n",
    "        rescale=scale,\n",
    "        rotation_range=rotation,\n",
    "        zoom_range=zoom,\n",
    "        width_shift_range=width_shift,\n",
    "        height_shift_range=width_shift,\n",
    "        shear_range=shear,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",) \n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        dtype='float32',\n",
    "        rescale=scale,\n",
    "        rotation_range=rotation,\n",
    "        zoom_range=zoom,\n",
    "        width_shift_range=width_shift,\n",
    "        height_shift_range=width_shift,\n",
    "        shear_range=shear,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 613 images belonging to 4 classes.\n",
      "Found 72 images belonging to 4 classes.\n",
      "Found 315 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=src_path_train,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory=src_path_valid,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=src_path_test,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 4\n",
    "\n",
    "CHANNELS = 3\n",
    "\n",
    "IMAGE_RESIZE = 224\n",
    "RESNET50_POOLING_AVERAGE = 'avg'\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'\n",
    "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "EARLY_STOP_PATIENCE = 1\n",
    "\n",
    "BATCH_SIZE_TESTING = 1\n",
    "\n",
    "STEPS_PER_EPOCH_TRAINING = 20\n",
    "STEPS_PER_EPOCH_VALIDATION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = 'imagenet'))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
    "# model.add(Dense(512, activation = DENSE_LAYER_ACTIVATION))\n",
    "# model.add(Dense(256, activation = DENSE_LAYER_ACTIVATION))\n",
    "# model.add(Dense(128, activation = DENSE_LAYER_ACTIVATION))\n",
    "model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "# Say not to train first layer (ResNet) model as it is already trained\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 2048)              8192      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 4)                 8196      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23604100 (90.04 MB)\n",
      "Trainable params: 12292 (48.02 KB)\n",
      "Non-trainable params: 23591808 (90.00 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(learning_rate = 0.01, momentum = 0.9, nesterov = True)\n",
    "model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "cb_checkpointer = ModelCheckpoint(filepath = './models/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - ETA: 0s - loss: 1.0429 - accuracy: 0.5416"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ariqhakim/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 8s 290ms/step - loss: 1.0429 - accuracy: 0.5416 - val_loss: 1.5231 - val_accuracy: 0.1562\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 5s 253ms/step - loss: 0.8954 - accuracy: 0.5840 - val_loss: 1.8087 - val_accuracy: 0.1562\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 5s 254ms/step - loss: 0.8629 - accuracy: 0.6378 - val_loss: 1.5018 - val_accuracy: 0.0938\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 5s 255ms/step - loss: 0.8177 - accuracy: 0.6444 - val_loss: 1.3873 - val_accuracy: 0.3438\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 5s 241ms/step - loss: 0.7606 - accuracy: 0.6688 - val_loss: 1.5619 - val_accuracy: 0.2500\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 5s 240ms/step - loss: 0.7558 - accuracy: 0.6705 - val_loss: 1.4141 - val_accuracy: 0.2188\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 5s 261ms/step - loss: 0.7139 - accuracy: 0.6884 - val_loss: 1.2576 - val_accuracy: 0.3438\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 5s 239ms/step - loss: 0.7103 - accuracy: 0.6917 - val_loss: 1.3184 - val_accuracy: 0.2188\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 5s 249ms/step - loss: 0.7115 - accuracy: 0.6754 - val_loss: 1.1426 - val_accuracy: 0.3438\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 5s 242ms/step - loss: 0.7296 - accuracy: 0.6803 - val_loss: 1.2213 - val_accuracy: 0.3438\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 5s 240ms/step - loss: 0.7166 - accuracy: 0.6966 - val_loss: 1.3788 - val_accuracy: 0.2500\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 5s 253ms/step - loss: 0.6800 - accuracy: 0.6998 - val_loss: 1.1274 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 5s 252ms/step - loss: 0.6900 - accuracy: 0.6900 - val_loss: 1.2288 - val_accuracy: 0.3750\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 5s 252ms/step - loss: 0.6742 - accuracy: 0.6835 - val_loss: 1.0593 - val_accuracy: 0.4688\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 5s 243ms/step - loss: 0.6990 - accuracy: 0.6982 - val_loss: 1.3400 - val_accuracy: 0.2188\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 5s 238ms/step - loss: 0.6231 - accuracy: 0.7308 - val_loss: 1.2156 - val_accuracy: 0.2188\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 5s 242ms/step - loss: 0.6695 - accuracy: 0.7276 - val_loss: 1.1970 - val_accuracy: 0.3438\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 5s 238ms/step - loss: 0.6316 - accuracy: 0.7341 - val_loss: 1.0835 - val_accuracy: 0.3125\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 5s 263ms/step - loss: 0.6229 - accuracy: 0.7243 - val_loss: 1.0373 - val_accuracy: 0.4688\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 5s 250ms/step - loss: 0.6282 - accuracy: 0.7423 - val_loss: 0.9009 - val_accuracy: 0.5312\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 5s 239ms/step - loss: 0.6516 - accuracy: 0.7129 - val_loss: 0.9735 - val_accuracy: 0.5938\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 5s 235ms/step - loss: 0.6122 - accuracy: 0.7325 - val_loss: 1.0146 - val_accuracy: 0.5625\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 5s 239ms/step - loss: 0.6036 - accuracy: 0.7423 - val_loss: 1.0679 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 5s 237ms/step - loss: 0.5841 - accuracy: 0.7618 - val_loss: 0.9303 - val_accuracy: 0.5625\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 5s 239ms/step - loss: 0.6343 - accuracy: 0.7276 - val_loss: 1.0038 - val_accuracy: 0.5000\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 5s 254ms/step - loss: 0.6555 - accuracy: 0.7080 - val_loss: 0.8585 - val_accuracy: 0.6562\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 5s 240ms/step - loss: 0.6237 - accuracy: 0.7308 - val_loss: 0.8756 - val_accuracy: 0.5938\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 5s 253ms/step - loss: 0.6173 - accuracy: 0.7423 - val_loss: 0.7549 - val_accuracy: 0.6875\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 5s 246ms/step - loss: 0.5871 - accuracy: 0.7586 - val_loss: 0.8312 - val_accuracy: 0.6562\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 5s 238ms/step - loss: 0.5969 - accuracy: 0.7488 - val_loss: 0.9808 - val_accuracy: 0.4688\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 5s 239ms/step - loss: 0.6236 - accuracy: 0.7227 - val_loss: 0.9776 - val_accuracy: 0.4688\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 5s 239ms/step - loss: 0.6302 - accuracy: 0.7276 - val_loss: 0.8723 - val_accuracy: 0.5938\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 5s 238ms/step - loss: 0.5481 - accuracy: 0.7667 - val_loss: 0.7632 - val_accuracy: 0.6562\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 5s 250ms/step - loss: 0.5698 - accuracy: 0.7732 - val_loss: 0.6271 - val_accuracy: 0.6250\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 5s 255ms/step - loss: 0.6002 - accuracy: 0.7341 - val_loss: 0.8378 - val_accuracy: 0.5938\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 5s 239ms/step - loss: 0.6082 - accuracy: 0.7406 - val_loss: 0.9993 - val_accuracy: 0.6250\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 5s 244ms/step - loss: 0.5734 - accuracy: 0.7504 - val_loss: 0.8550 - val_accuracy: 0.5938\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 5s 246ms/step - loss: 0.5988 - accuracy: 0.7488 - val_loss: 0.6402 - val_accuracy: 0.7812\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 5s 237ms/step - loss: 0.6341 - accuracy: 0.7243 - val_loss: 0.8795 - val_accuracy: 0.5625\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 5s 240ms/step - loss: 0.6099 - accuracy: 0.7423 - val_loss: 0.8343 - val_accuracy: 0.6562\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 5s 241ms/step - loss: 0.5376 - accuracy: 0.7700 - val_loss: 0.8611 - val_accuracy: 0.5625\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 5s 242ms/step - loss: 0.5285 - accuracy: 0.7928 - val_loss: 0.9802 - val_accuracy: 0.5938\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 5s 247ms/step - loss: 0.5764 - accuracy: 0.7390 - val_loss: 0.7542 - val_accuracy: 0.6250\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 5s 241ms/step - loss: 0.5600 - accuracy: 0.7520 - val_loss: 0.8070 - val_accuracy: 0.6250\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 5s 245ms/step - loss: 0.5868 - accuracy: 0.7651 - val_loss: 0.8763 - val_accuracy: 0.5312\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 5s 239ms/step - loss: 0.5772 - accuracy: 0.7504 - val_loss: 0.8937 - val_accuracy: 0.5938\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 5s 238ms/step - loss: 0.5639 - accuracy: 0.7553 - val_loss: 0.9446 - val_accuracy: 0.5938\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 5s 236ms/step - loss: 0.5827 - accuracy: 0.7406 - val_loss: 1.1578 - val_accuracy: 0.5312\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 5s 241ms/step - loss: 0.5774 - accuracy: 0.7520 - val_loss: 0.6900 - val_accuracy: 0.6562\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 5s 239ms/step - loss: 0.5647 - accuracy: 0.7667 - val_loss: 1.0382 - val_accuracy: 0.4688\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "        callbacks=[cb_checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 7s 16ms/step - loss: 1.1129 - accuracy: 0.5365\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
